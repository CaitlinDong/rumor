\chapter{Summary of Contributions and Future Work}
\label{ch:conclusion}

\section{Contributions}
We have introduced a setting to do inference in the presence of large amounts of
data governed by an underlying stochastic model. Within this setting, we have
derived an online time series classification method and an associated
implementation that is simple, efficient, and scalable. To investigat the
classification performance of our method, we applied it to the task of
predicting trending topics on Twitter. We showed the method's flexibility by
analyzing the effects of the algorithm parameters, and quantified the tradeoffs
between relative detection time, true positive rate, and false positive
rate. Finally, we demonstrated the method to be succesful in predicting trending
topics on Twitter, at a low error rate, often before they are detected by
Twitter.

\section{Future Work}
Possible directions for future work include the following:

\begin{itemize}
\item To take advantage of the structure in large amounts of unlabeled data, it
  would be desirable to extend the theory and algorithms presented in this
  thesis to handle large amounts of unlabeled data.
\item I'm going to think about this some more. I am still struggling a bit with
  the big picture view. If you think of something, please let me know.
\end{itemize}

