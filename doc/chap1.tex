%% This is an example first chapter.  You should put chapter/appendix that you
%% write into a separate file, and add a line \include{yourfilename} to
%% main.tex, where `yourfilename.tex' is the name of the chapter/appendix file.
%% You can process specific files by typing their names in at the 
%% \files=
%% prompt when you run the file main.tex through LaTeX.
\chapter{Introduction}
\label{ch:intro}
\section{Motivation}

Detection, classification, and prediction of events in temporal streams of
information are ubiquitous problems in science, engineering and society. From
detecting malfunctions in a production plant, to predicting an imminent market
crash, to revealing emerging popular topics in a social network, extracting
useful information from time-varying data is fundamental for understanding the
processes around us and making decisions.

In recent years, there has been an explosion in the availability of data related
to virtually every human endeavor --- data that demands to be analyzed and
turned into valuable insights. Massive streams of user generated documents, such
as blogs and tweets, as well as data from portable electronic devices, provide
an amazing opportunity to study the dynamics of human social interaction online
and face to face \cite{Pentland1}\cite{Pentland2}. How do people make decisions?
Who are they influenced by? How do ideas and behaviors spread and evolve? These
are questions that have been impossible to study empirically at scale until
recent times. In healthcare, records of over-the-counter medication
sales \cite{Wagner} as well as search engine queries \cite{Xu} can anticipate the
outbreak of disease and provide insight into the most effective ways to limit
its spread. Particle collision experiments at the Large Hadron Collider generate
more than 15 petabytes of data \cite{Andreeva} every year that promises to reveal
fundamental physical truths.

Such large quantities of data present both opportunities and challenges. On the
one hand, enough data can reveal the hidden underlying structure in a process of
interest. On the other hand, making computations over so much data at scale is a
challenge. Fortunately, in recent years, advances in distributed computing have
made it easier than ever to exploit the structure in large amounts of data to do
inference at scale.

% TODO: transition
All of the examples mentioned above share a common setting. There exists an
underlying process whose observable properties generate time series. Using these
time series, one may wish to do inference such as detecting anomalous events,
classifying the current activity of the time series, or predicting the values of
the time series at some future point.

This is difficult to do in general. Many real-world processes defy description
by simple models. A quote from ``The Unreasonable Effectiveness of
Data''\cite{Halevy} by Halevy, Norvig, and Pereira sums this up:
\begin{quote}
``{\em Eugene Wigner's article `The Unreasonable Effectiveness of Mathematics in
    the Natural Sciences' examines why so much of physics can be neatly
    explained with simple mathematical formulas such as $f = ma$ or $e =
    mc^2$. Meanwhile, sciences that involve human beings rather than elementary
    particles have proven more resistant to elegant mathematics. Economists
    suffer from physics envy over their inability to neatly model human
    behavior. An informal, incomplete grammar of the English language runs over
    1,700 pages. Perhaps when it comes to natural language processing and
    related fields, we're doomed to complex theories that will never have the
    elegance of physics equations. But if that's so, we should stop acting as if
    our goal is to author extremely elegant theories, and instead embrace
    complexity and make use of the best ally we have: the unreasonable
    effectiveness of data.}''
\end{quote}

Like language, the behavior of complex systems rarely admits a simple model that
works well in practice. Like machine translation and speech recognition, there
is an ever growing amount of data ``in the wild'' about processes like
epidemics, rumor-spreading in social networks, financial transactions, and
more. The inadequacy of simple models for complex behavior requires an approach
that embraces this wealth of data and it highlights the need for a unified
framework that efficiently exploits the structure in that data to do detection,
classification, and prediction in time series.

In this thesis, we study the problem of prediction in a complex system using
large amounts of data. Specifically, we focus on binary classification of time
series and ask whether we can tell apart ``events'' from ``non-events'' given
sufficient historical examples. We apply this to the problem of {\em trending
  topic} detection on Twitter and show that we can reliably detect trending
topics before they are detected as such by Twitter. At the same time, we aim to
introduce a more general setting for doing inference in time series based on a
large amount of historical data.

%In this thesis, we focus on the problem of time series classification. Rather
%than imposing any structure on our model, however, we wish to do this in a
%nonparametric fashion by relying directly on the data. In the process, we
%introduce a general setting for supervised learning in which the model is
%specified by unknown latent sources

\section{Previous Work}

% ``deviation from baseline models''

A popular approach to detecting emerging popular topics in document streams is
to measure the deviation of topics' activity relative to some baseline. Ihler et
al. \cite{Ihler} propose an event detection framework based on time-varying
Poisson processes, in which a baseline Poisson rate is estimated in a sliding
window and anomalies are considered to be deviations from a local
baseline. Becker et al. \cite{Becker}, Cataldi et al. \cite{Cataldi}, and
Mathioudakis and Koudas. \cite{Mathioudakis} all group terms together to form topics
and use a combination of features including temporal activity and social
authority and interaction to detect trending topics.

% ``actually modeling the underlying process models''
Many approaches to emergent topic detection specifically, and detecting
outbreaks in networks more generally, involve explicit models of a spreading
process over a network.  Asur et al. \cite{Asur} model the formation, persistence
and decay of trending topics on Twitter using a branching process
model. Shtatland and Shtatland \cite{Shtatland} investigate outbreak phenomena based on an
underlying SIR model for spreading. They train a stationary autoregressive model
for spreading activity and declare anomalies when the model starts to become
non-stationary. Gruhl et al. \cite{Gruhl} use a cascade model to study the propagation
of information through a social network. They posit that topic activity is
composed of ``spikes'' and ``chatter'' and characterize individuals in the
network in terms of different posting behaviors. They then use an EM algorithm
to infer which edges may have been active in the spread of the topic. For
modeling the activity of topics in a document stream, models not based on
networks also exist. Kleinberg \cite{Kleinberg} models a stream of documents using an
infinite state automaton and computes optimal state sequences based on the data
to infer how the observed activity was generated.

A third class of methods operates on large collections of time series as a way
to reason about the underlying hidden process without explicitly modeling that
process. Along those lines a number of trajectory clustering methods have
emerged recently. Gaffney and Smyth \cite{Gaffney} propose a method for trajectory
clustering, where each cluster is modeled as a prototype trajectory with some
noise. They produce low dimensional representations of the trajectories by using
regression models and train a finite mixture model on the regression model
components. Munaga et al. \cite{Munaga} offer a more flexible approach that is able to
identify regions of high density that are separated from one another by regions
of low density as well as automatically determine the number of clusters. In the
realm of supervised learning, McNames \cite{McNames} uses a ``nearest trajectory''
strategy to do prediction in time series. Lenser and Veloso \cite{Lenser} propose a
method for nonparametric time series classification in time series produced by a
process consisting of different underlying states, in which pieces of the time
series are classified as having been produced by a certain state.

\section{Our Approach}
Simple, parametric models prove ineffective at modeling many real-world complex
systems. To resolve this, we propose a nonparametric framework for doing
inference on time series. In this model, we posit the existence of a set of {\em
  latent source} time series, or signals, each corresponding to a prototypical
event of a certain type, and that each observed time series is a noisy
observation of one of the latent time series.

In the case of classification, an observed signal, is compared to two sets of
{\em reference} signals --- one consisting of positive examples and the other of
negative examples. We posit that the observation belongs to the positive
(resp. negative) class if it was generated by the same latent source as one of
the positive (resp. negative) examples. To do classification, we compute the
class probabilities conditioned on the observation. In our model, doing so
involves a surprisingly simple computation --- to see how likely it is that an
observation belongs to a certain class, one simply computes the distances from
the observation to the reference signals in that class. This allows us to infer
the class in a nonparametric fashion directly from the data without specifying
any model structure.

\subsection{Application: Detecting Outbreaks of Popular Topics on Twitter}
As an application, we apply the latent source model to the problem of detecting
emerging popular topics (called {\em trends}) on Twitter. Twitter is a real-time
messaging service and information network whose users can post short (140
characters or fewer) messages called {\em Tweets}. Tweets are public by default
and broadcast to the users' {\em followers}. Users can engage in conversation
with one another and join a potentially global conversation on a variety of
topics being discussed. Inevitably, some topics, such as a breaking news event,
gain sudden popularity on Twitter. Twitter surfaces such topics in the service
as a list of {\em trending topics}. We apply our method to the task of detecting
trending topics and show its effectiveness by comparing our results to the
official topics detected by Twitter. Our method can detect trends in advance of
Twitter 79\% of the time, with a mean early advantage of 1.43 hours, while
maintaining a 95\% true positive rate and a 4\% false positive
rate. Furthermore, we are able to do this using only a sample --- 10\% --- of
the Tweets in a period of time. Lastly, we show that our method is flexible and
can be tuned to reflect a wide variety of tradeoffs between false positive rate,
true positive rate, and relative detection time.
