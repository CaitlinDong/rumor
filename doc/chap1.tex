%% This is an example first chapter.  You should put chapter/appendix that you
%% write into a separate file, and add a line \include{yourfilename} to
%% main.tex, where `yourfilename.tex' is the name of the chapter/appendix file.
%% You can process specific files by typing their names in at the 
%% \files=
%% prompt when you run the file main.tex through LaTeX.
\chapter{Introduction}
\label{ch:intro}
\section{Motivation}

{\bf Get to the point of what this is about and what your contributions are in
  the first couple of sentences. Then you can elaborate.}

Detection, classification, and prediction of events in temporal streams of
information are ubiquitous problems in science, engineering and society (TOO
BROAD?). From detecting malfunctions in a production plant, to predicting an
imminent market crash, to revealing emerging popular topics in a social network,
extracting useful information from time-varying data is fundamental for
understanding the processes around us and making decisions.

(The method does not require that the indpendent variable is time.)

In recent years, there has been an explosion in the availability of data related
to virtually every human endeavor --- data that demands to be analyzed and
turned into valuable insights. Massive streams of user generated documents, such
as blogs and tweets, as well as data from portable electronic devices, provide
an amazing opportunity to study the dynamics of human social interaction online
and face to face (cite Pentland?). How do people make decisions? Who are they
influenced by? How do ideas and behaviors spread and evolve? These are questions
that have been impossible to study empirically at scale until recent times. In
healthcare, records of over-the-counter medication sales (cite National Retail
Data Monitor) as well as search engine queries can anticipate the outbreak of
disease and provide insight into the most effective ways to limit its
spread. Particle collision experiments at the Large Hadron Collider generate
more than 15 petabytes (SOURCE?) of data every year that promises to reveal the
most fundamental physical truths.

(Does the physics example really fit in here? It's not a network example, but it
looks like we won't be using anything network specific in the method.)
%In hospitals, continuous patient monitoring can help identify problematic
%situations early on and allow medical professionals to make life-saving
%decisions.

%The recent financial meltdown (ugh cliche) highlights the need for increased
%efforts ??? what about Black Swan events, etc... of course there are things we
%can't predict, but there should be plenty that we can that are
%important... what's a good example?

At the same time, advances in distributed computing have made it easier than
ever to exploit the structure in that data to do inference at scale. ELABORATE?

All of the examples mentioned above share a common setting. There is an
underlying process whose observable properties generate timeseries. We would
like to observe those timeseries to
\begin{itemize}
\item detect anomalous events
\item classify the current activity of the timeseries into event types
\item predict the values of the timeseries at some future point.
\end{itemize}

This is difficult to do in general. Many real-world processes defy simple models
that describe their behavior. A quote from ``The Unreasonable Effectiveness of
Data'' by Halevy, Norvig, and Pereira sums it up:
\begin{quote}
``{\em Eugene Wigner's article `The Unreasonable Effectiveness of Mathematics in
    the Natural Sciences' examines why so much of physics can be neatly
    explained with simple mathematical formulas such as $f = ma$ or $e =
    mc^2$. Meanwhile, sciences that involve human beings rather than elementary
    particles have proven more resistant to elegant mathematics. Economists
    suffer from physics envy over their inability to neatly model human
    behavior. An informal, incomplete grammar of the English language runs over
    1,700 pages. Perhaps when it comes to natural language processing and
    related fields, we're doomed to complex theories that will never have the
    elegance of physics equations. But if that's so, we should stop acting as if
    our goal is to author extremely elegant theories, and instead embrace
    complexity and make use of the best ally we have: the unreasonable
    effectiveness of data.}''
\end{quote}

Like language, the behavior of complex systems rarely admits a simple model that
works well in practice. Like machine translation and speech recognition, there
is an ever growing amount of data ``in the wild'' about processes like
epidemics, rumor-spreading in social networks, financial transactions, and
more. The inadequacy of simple models for complex behavior requires an approach
that embraces this wealth of data and it highlights the need for a unified
framework that efficiently exploits the structure in that data to do detection,
classification, and prediction in timeseries.

\section{Previous Work}
Maybe start from more specific things (Twitter event detection, etc) and move to
more general/abstract things and conclude with nonparametric timeseries methods.

Event detection in timeseries.

Classification in timeseries.

Prediction in timeseries.

Models with theoretical justification for the underlying model of the
process. Network cascade models. Branching process models.  Epidemics, Social
Network rumor spreading

(Nonparametric) timeseries clustering methods

Explicit generative model? Mixture model?

In principle, no tunable threshold required, because of explicit probabilistic
model, threshold is just 1.

Experimental results note. It could just be that the false positive rate is all
of the things that have high volume that we weren't able to normalize away,
except that there's only a few of them, so maybe what we're doing is not that
impressive. However, if we compare to the unnormalized ones, we do (get solid
confirmation) much better. Question: What false positive rate should we expect,
even with the best method (just by looking at the data)?


Show experimenta; results for multiple data sets to make sure you didnt jyst
tweak the signal normalization for a partucular dataset

\section{My Approach}
Simple models prove ineffective when exposed to the vast variety of real world
situations. [SAY MORE ABOUT THIS] I propose a nonparametric framework for doing
inference on timeseries (VAGUE). In this model, we posit that there exist of a
set of latent timeseries, each corresponding to a prototypical event of a
certain type, and that each observed timeseries is a noisy observation of one of
the latent timeseries.

\subsection{Anomaly Detection}
A timeseires in a given window is compared to a set of reference timeseries that
represents ``normal'' events. We compute the probability that the observed
timeseries was generated by a latent timeseries corresponding to a timeseries in
the reference set. We then declare observations with low probability to be
anomalies.

\subsection{Classification}
A timeseries in a given window is compared to two {\em reference} sets of
timeseries --- one consisting of positive examples and the other of negative
examples. We want to find out whether it is more likely that the observed
timeseries was generated by one of the latent timeseries in the positive
reference set or one of the latent timeseries in the negative reference set.

\subsection{Prediction}
A timeseries in a given window is compared to a single reference set of
timeseries. We want to find out the probability that the observed timeseries was
generated from the same latent timeseries as each of the timeseries in the
set. We then compute the most likely change in the observed timeseries by
observing the changes in each reference timeseries and weighting the change by
the probability that the observed timeseries and the reference timeseries were
generated by the same latent timeseries.
 
************Lots of work in clustering, but this has an explicit probabilistic
model.

\subsection{Application: Detecting Outbreaks of Popular Topics on Twitter}
As an application, I apply the method (CALL IT SOMETHING) to the problem of
detecting emerging popular topics (called {\em trends}) on Twitter. I use a set
of labeled examples of timeseries correspondingn to topics that eventually
became trending topics and topics that did not. I then perform online
classification of a given topic to label it as trending or not trending at a
particular time.  ***********Talk about results and main contributions.
